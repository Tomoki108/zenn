---
title: "[読書メモ] System Design Interview – An insider's guide"
emoji: "🧙🏼‍♂️"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["読書メモ", "ソフトウェアアーキテクチャ"]
published: false
---

システムデザイン（インタビュー対策）に関するベストセラーの、個人的読書メモ。
[amazon リンク](https://www.amazon.co.jp/-/en/Alex-Xu/dp/B08CMF2CQF)

# Chapter 1: Scale From Zero To Millions Of Users

**全ての tier で冗長性と可用性を高めるべし。レイテンシーも低くすべし。**

- サーバーは 1 台固定ではなく最低 2 台以上を起動させ、**ロードバランサー**でリクエストを振り分ける。
  - 負荷に応じて台数を増やす。（**オートスケーリング**）
  - ロードバランサーの public ip のみ公開し、サーバー自体はロードバランサーから private ip によってアクセスする。
- DB は **primary/standby** 構成にし、前者に write リクエストを、後者に read リクエストを振り分け、primary=>secondary の**データレプリケーション**を行う。
  - primary に障害があれば standby を primary に昇格させ、standby を増やす。standby に障害があれば、standby を増やす。
- DB へ頻繁に問い合わせられ、かつ更新頻度の低いデータは、**キャッシュ**システムに保存する。
  - キャッシュには適切な有効期限を設定する。
  - 問い合わせに対してはキャッシュがあればそれを返し、なければ DB に問い合わせそれを返す。キャッシュにも保存する。
  - DB 更新とキャッシュの更新は、トランザクションを用い一貫性が常に保たれるようにする。
- 静的データ（HTML、CSS、JS）は **CDN（Contents Delivery Network）** で提供する。
  - CDN の世界各地のサーバーの、ユーザーに最も近いものから自動で配信できる。
- サーバーは**ステートレス**にする。セッション（ユーザーの認証情報）をサーバー内の RAM やファイルシステムに保存しない。オートスケーリングやフェイルオーバーの障害になる。
  - セッション情報などは外部ストレージに保存する。速度が求められるので NoSQL も有力。
- システム群は、複数のデータセンターに冗長化する。DB 等はレプリケーションして生合成を保つ。
  - ロードバランサーはユーザーの地理によって適切なデータセンターにルーティングする。（**GeoDNS-routed**）
- バッチ処理は、Worker サーバーを用意し、API サーバーから**メッセージキュー**を介してタスクに取り組む。API サーバーとは独立してスケーリングできるようになる。
- ツールを使いあらゆるログを収集し、ホストレベルメトリクス（ex, CPU usage）、集約レベルメトリクス（ex, DB tier performance）、KPI（ex, 収益、CR）などの**メトリクス**を監視する。見やすいダッシュボードを作る。
- DB を**シャーディング**によって水平スケーリングする。DB をシャードという単位に分割し、データを適切なパーティションキー（ex, id）から生成した ハッシュによって、どのシャードに格納するか切り分ける。高速なデータへのアクセスが可能になる。
  - データの増加に応じてシャードを追加したり、既存のシャードを更に分割するときは**リシャーディング**（データの再配置）を行う。
  - シャードにまたがるデータに対し連結クエリを実行したくなったときは、DB の非正規化でシャード内でデータが完結するようにしたり、**マテリアライズドビュー**を用意したりしておく。

# Chapter 2: Back-of-the-envelope Estimation

## 覚えるべき数字

- 2 の乗数、バイト単位について覚えましょう。
  ::: details 表
  ![image](/images/202502_system_design/chapter2_power_of_two.png)
  :::

- 主要なレイテンシーを覚えましょう。
  ::: details 表
  ![image](/images/202502_system_design/chapter2_latency.png)
  :::

- **重要**
  - メモリアクセスは早いがディスクアクセスは遅い。ディスクアクセスは可能な限り避ける。
  - 単純な圧縮アルゴリズムは早い。ネットワーク越しのデータ転送は可能なら事前に圧縮を。
  - 異なるリージョンのデータセンター間の通信は時間がかかる。

### QPS(Query Per Seconds)の見積もり

Ex, Twitter

Given:

- 300 million monthly active users.
- 50% of users use Twitter daily.
- Users post 2 tweets per day on average.
- 10% of tweets contain media.
- Data is stored for 5 years.
- Average tweet size:
  - tweet_id 64 bytes
  - text 140 bytes
  - media 1 MB

Estimations:

- **Daily active users (DAU)**: `300 million * 50% = 150 million`
- Tweets QPS: `150 million * 2 tweets / 24 hour / 3600 seconds = ~3500`
- Peak QPS: `2 * QPS = ~7000`
- Media storage: `150 million * 2 * 10% * 1 MB = 30 TB per day`
- 5-year media storage: `30 TB * 365 * 5 = ~55 PB`

#### Tips

- 計算結果をメモに書く。
- 数字を丸める。
- 前提としてバイトの変換等に慣れておく。
- **QPS, peak QPS, storage, cache**などがよく聞かれる。

# Chapter 3: A Framework For System Design Interviews

## step1. 問題を認識して設計のスコープを明確にする / 3~10 min

「ニュースフィードを設計してください」

- web or mobile? both?
- 最低限のユースケースは何？
- Daily Active User の数は？
- 機能の詳細

  - フィードは友達の記事？時系列順？何らかの重み順？
  - ユーザーは友達を何人もてる？
  - ニュースはテキスト？イメージやビデオを含む？

## step2. 全体設計を提案し同意を得る / 10~15 min

::: details このくらいの全体設計をホワイトボードに書く
![image](/images/202502_system_design/chapter3_blueprint.png)
:::

## step3. 詳細を設計する / 10~25 min

どの部分を詳細に設計して欲しいのか明確にする。

重要なユースケース。ex, 「ニュースの投稿」「ニュースフィードの取得」
あるいは重要なコンポーネント。ex, 「フィードのキャッシュ」「リクエストのレートリミッター」

::: details 全体設計に書き足す
![image](/images/202502_system_design/chapter3_detailed_blueprint.png)
:::

## step4. Wrap Up / 3~5 min

これまでに作った設計をもう一度説明して振り返ると良い。

また、最後に以下の様なことが聞かれることが多い。

- ボトルネックと改善ポイント
- エラーケースからの復帰
- 運用の問題。どの様にログを取って監視する？新機能はどの様にリリース（ロールアウト）する？
- ユーザーが 10 倍になったらどうする？

## Dos

- 確認のために常に質問を。勝手に前提を置かない。
- 要件を理解する。不確かなまま進めない。
- 可能なら複数の提案を。アイデアをインタビュアーにぶつけよう。（インタビュアーは仲間。）
- **全体設計に合意してから**、重要な場所の詳細設計に入る。

## Dont's

- **典型的な質問への対策は怠らない。**
- 要件や期待を確認するまで、ソリューションにジャンプしない。
- 質問を臆さない、黙って考えない。
- インタビュアーが終わりというまで終わらない。

# Chapter 4: Design A Rate Limiter

## step1. 問題を認識して設計のスコープを明確にする / 3~10 min

- server side or client side?
  - => sever side
- 何でレート制限する？IP、UserID？
  - => up to you
- システムのスケールは？スタートアップ？巨大なシステム？
  - => 大規模なユーザーにも対応できる様にして。
- 分散型システムでも機能する必要はある？
  - => yes
- ユーザーにレート制限中と伝える必要はある？
  - => yes

## step2. 全体設計を提案し同意を得る / 10~15 min

### どこにレートリミッターを置くか

- サーバー
  - 実装が必要だがリミッターの挙動を比較的自由にできる。分散システムと相性が悪い。
- ミドルウェア（外部サービス）
  - 楽。利用するサービスによってはリミッターの挙動が限られたオプションになる。分散システムと相性が良い。

### どこにレートリミット用のカウンター（またはログなど）を保存するか

- DB は適さない。ディスクアクセスは遅い。
- In-Memory Cache （Redis など）が適当。データを一定期間で expired にもできる。

::: details blueprint
![image](/images/202502_system_design/chapter4_blueprint.png)
:::

## step3. 詳細を設計する / 10~25 min

### レートリミットのルールはどこに保存されている？

- 何らかの永続化ディスクに保存する。Worker が定期的にディスクにアクセスしてキャッシュを作成する。ミドルウェアはキャッシュを参照する。

### リミットオーバーのリクエストのハンドリングはどうなる？

- ミドルウェアが Redis にカウンター等の情報を取得。キャッシュから取得したルールと照合して、
  - リミットオーバーなら 429。header に`X-Ratelimit-Retry-After`などを付与。リクエスト自体はドロップするか、メッセージキューに入れる。（要件次第。）
  - オーバーしていないならサーバーへ処理を進める。Redis へカウンター等も記録する。レスポンスヘッダーに`X-Ratelimit-Remaining`, `X-Ratelimit-Limit`などを付与する。

::: details detailed blueprint
![imgae](/images/202502_system_design/chapter4_detailed_blueprint.png)
:::

### 分散システムだったとして、気にする必要があることは？

- 状態の競合（Race Condition）。Dirty Read など。transaction lock するのがシンプルだが遅くなる。「Lua Script and sorted sets data structure in Redis」というソリューションが有名だったりする。

- 同期の問題。Redis 等を centerized Data store として使うと良い。各レートリミッターが別々のデータストアを参照している状態は、スケーラブルじゃない。

### モニタリング

- レートリミットアルゴリズムが適切かどうか見た方がいい。

  - 例えばタイムセールなどのトラフィックバーストに対応できていない様だったら、Token Bucket への変更を考えるなど。

- レートリミットのルールが適切かどうか見た方がいい。
  - 通常の範囲のリクエストが跳ねられていたら問題。

## step4. Wrap Up / 3~5 min

以下の様な話題を出してもいい。

- Hard vs soft rate limiting?
  - リミット超過のリクエストは認めないのか、短時間だけ認めるか。
- アプリケーションレイヤー以外でのレートリミット。
  - ex, Iptable (OSI layer 3)での IP 制限。
- クライアント側の効率化
  - クライアントキャッシュを利用して API call を減らす
  - レートリミットをコードに織り込む。429 をハンドリングする。

---

## レートリミットの各種アルゴリズム

::: details Token Bucket / Leaking Bucket / Fixed Window Counter / Sliding Window Log / Sliding Window Counter

## Token Bucket

- バケットに決められた時間に決められた量のトークンを補充。キャパオーバーなら補充しない。（ex, cap 4 のバケットに 2 tokens/sec を補充。）
- ユーザーリクエストのたびにトークンを一つ消費。トークンが足りなければ 429。
- ユーザーごと \* API Endpoint ごとにバケットを用意する。

- pros
  - token が残っている限りリクエストできるため、短いトラフィックのバーストに対応可能。
  - `token_count, last_refill_time, cap, rate`を保持するだけでいいため、メモリ効率がいい。
- cons
  - バケットのキャパ、トークンのリフィルレートのチューニングが難しい。

## Leaking Bucket

- サイズが設定してある FIFO キューにリクエストをため、等間隔（ex, 1 req/sec）で処理していく。キューがいっぱいの場合 429。

- pros
  - キューのサイズ上限によりメモリ効率がいい。
  - 等間隔でのリクエスト処理が必要な場合に適している。
- cons
  - 古いリクエストでキューがいっぱいの時に、それ以降のリクエストが全て処理されない。
  - キューのサイズ、リクエストの処理のレートのチューニングが難しい。

## Fixed Window Counter

- 時刻をウィンドウに分割。（ex, 1:00 00~59, 1:01 00 ~59, ...）ウィンドウごとにリクエスト上限までしかリクエストできない。リクエストごとにウィンドウのカウンターをプラスし、上限を超えていれば 429。

- pros
  - `window_start, window_size, conter`だけ保持すればいいのでメモリ効率がいい。
  - 一定時間でクォータをリセットできる。
- cons
  - トラフィックバーストの際に、ウィンドウ i の終わり、ウィンドウ i+1 の始まりを見ると 100 req / 1 min のような決まったレートリミットを超えていることがある。

### Sliding Window Log

- リクエストのタイムスタンプをログに記録する。2 req/min だった場合、リクエストが来た時に直近一分のログが 1 個以下ならリクエストを通す。そうでないならログを記録しつつ 429。直近一分より前のログは削除する。

- pros
  - 正確なレート制限。上記例だと、どの一分を切り取ってもリクエストは 2 件以上処理されない。
- cons
  - メモリ効率が悪い。リクエストがリジェクトされてもログに残る。バーストの時に大量のログが残る。

### Sliding Window Counter

- Fixed Window Counter と同様に時刻をウィンドウに分割し、ウィンドウごとに上限までしかリクエストできない。カウンターで管理。
- ただし、あるウィンドウで開始時刻からウィンドウサイズの例えば 30%の時刻に到達するまでは、リクエスト上限が「前のウィンドウのカウンターの合計 \* 70%」を引いたものになる。

- pros
  - Fixed Window Counter と同様にメモリ効率がいい。
  - Fixed Window Counter の、ウィンドウの境目前後で見るとリクエスト上限を超えかねない問題を概ね克服している。
- cons
  - ウィンドウの境目でリクエスト上限を超えないことを完全には保証していない。ただし理論上ごくごく低確率らしい。

:::

# Chapter 5: Design Consistent Hashing

- 分散キャッシュサーバーへのデータの保存・取得を行うとき、データのキーをハッシュ化した数字を元にサーバーを決定する。`severIdx := hash(key)%numOfServer`
- しかしサーバーの台数を増減した場合、大量のデータの再配置を余儀なくされる。
- **Consistent Hashing**は、サーバー台数の増減時の再配置が 平均 `numOfKey / numOfServer`で済むテクニック。
  - ハッシュ化されたキーが取りうる値のリストの、先頭と末尾がつながったデータ構造（**Hash Ring**）を用意する。
  - 各サーバーについて、IP や名前をもとにハッシュを作成し、Hash Ring の該当する位置に目印をつける。
  - 保存したいデータが来たら、ハッシュキーの位置から時計回りで Hash Ring を探索し、最初に見つけたサーバーに格納することにする。
- Consistent Hashing の問題
  - Hash Ring へサーバーを初期配置するときに、間隔が均等とは限らない。
  - サーバーを減らせば Hashi Ring でその手前に位置するサーバーへの割り当てが増える。逆も然り。各サーバーの割り当てを均等に保つことができない。
  - => **Virtual Node**を Hash Ring によしなに配置することで、各サーバーへの割り当てを均等にする。Virtula Node は既存のいずれかのサーバに紐づくものとし、各サーバーの Original Node or Virtual Node の隣接ノードとの距離の和が等しくなるようにする。

# Chapter 6: Design A Key-value Store

- **CAP Theorem** (CAP 定理)
  - 分散システムにおいて、 Consistency（一貫性）、 Availability（可用性）、Partition Torelance（ネットワーク分断耐性）の３つ全てを叶えることはできず、トレードオフになる。
    - CP: 可用性を犠牲にして一貫性と分断耐性をサポート。すべてのノードが整合するまで読み書きできない。
    - AP: 一貫性を犠牲にして可用性と分断耐性をサポート。最新ではない値を取得することんもあるが、いつでも読み書きできる。
    - **CA: 分散システムではネットワーク分断が不可避であるため存在しない**
- データ分割
  - Consistent Hash を使えば、サーバー台数の増減が可能になり、オートスケーリングにも対応できる。
  - 性能の高いサーバーには多くのバーチャルノードを紐づけることで、サーバー群が Heterogeneity（異質性）を持つことも可能。
- データレプリケーション
  - 高可用性、信頼性のためにデータは任意の数のノードに複製が必要。データが格納されるノードから Hash Ring を時計回りに探索し、最初の N 個のノードに複製する。
    - 同じサーバーに紐づくバーチャルノードは無視。
    - 各サーバーは別のデータセンターにあるのが理想。
- 一貫性
  - 3 種類のパラメターを設定する必要がある。一貫性とレイテンシーのトレードオフに影響。
    - `N`: num of replica nodes
    - `W`: write quorum. write operation must be acknowledged by W replicas
    - `R`: read quorum. read operation must be acknowledged by R replicas
      - `R = 1 && W = N`: fast read
      - `W = 1 && R = N`: fast write
      - `W + R > N`: strong consistency
  - **一貫性モデル**
    - 強い一貫性：クライアントは常に最新のデータを取得する
    - 弱い一貫性: クライアントは最新でないデータを取得しうる
    - 結果一貫性: 十分な時間をかけて、すべての更新は伝播し一貫性が取れる
- **不整合の解消: バージョン管理**
  - あるデータについて、それを保持するノードは`[]{node, version}`の構造をした**ベクタークロック**というデータを保持する。
  - データが更新される際に、ベクタークロックに自身のノードのペアがあればそのバージョンをインクリメントする。なければペアを追加する。
    - その前段で、決められた数の他のノード（quorum）からベクタークロックを取得し、それらのベクタークロックをマージして不整合を解消する。その上でベクタークロックの更新を行う。参照したノードのベクタークロックはその時点では更新しない。その後のレプリケートによって徐々に更新されたベクタークロックの内容が伝播する。
  - ベクタークロックの cons は、競合解消のロジックを実装する必要があること、長期間のベクタークロックの履歴の保持はデータ容量的に無理なので古いものを消す必要があること。（ただし Amazon ではこれによる問題は起きたことないらしい。）
- **障害の検知**
  - **ゴシッププロトコル**
    - 各ノードは自身のハートビートカウンタを持ち、定期的にインクリメントする。
    - 各ノードは全ノードのハートビートリストを持つ。
    - 各ノードは定期的にランダムなノードリストに自身のハートビートを送信する。受信側はリストを更新し、さらに受け取ったハートビートを他のノードに伝播する。
    - 行って時間ハートビートが更新されなかったノードをオフラインとみなし、複数のノードによってオフラインとみなされたノードはオフラインで確定。
- **一時的な障害の対応**
  - ハッシュリング上から最初の W 台の健全なサーバーを書き込み用に、最初の R 台の健全なサーバーを読み込み用とし、応答させる。**Sloppy Quorum**
  - 代替ノードはヒントという形で書き込まれたデータを保持し、オフラインになっていた本来のノードが復旧した場合、データを送信して自身のヒントを削除する。**ヒンテッドハンドオフ**と呼ばれる。
  - 恒久的な障害の対応はマークルツリーというデータ構造によるアンチエントロピープロトコルというもので行うらしいが省略。
- **システム構成**
  - クライアントは`get(key)`, `put(key, val)`という API で通信
  - **コーディネータ**は、クライアントと KVS の間のプロキシとして機能するノード。データの保存先（レプリカ）のノードはハッシュ化されたキーによって決定するが、どれがコーディネータになるかは実装による。
  - ノードは Consistent Hash によって Hash Ring に分散されている。
  - ノードの追加や移動は自動で行われる。
  - すべてのノードが同じ責任を負うので単一障害点はない。(但し読み込みしか対応していないノードがあることもある。)
- **各ノードの役割**
  ![imgae](/images/202502_system_design/ch6_node_role.png)
- **書き込みフロー**
  ![image](/images/202502_system_design/ch6_write_flow.png)
- **読み込みフロー（キャッシュヒットなし）**
  ![image](/images/202502_system_design/ch6_read_flow.png)
- **読み込みフロー（キャッシュヒット）**
  ![image](/images/202502_system_design/ch6_read_flow_cache_hit.png)
- **まとめ**
  ![image](/images/202502_system_design/ch6_wrapup.png)

# Chapter 7: Design A Unique Id Generator In Distributed Systems

## 1. 問題を理解し設計範囲を明確にする ~10 min

- ユニーク ID ジェネレーターの特徴は？
  - 作成時間でソート可能
- ユニーク ID で使える文字は？長さは？
  - 数字のみ 64 ビット
- システムの規模は？
  - 1 万個/1 秒 生成できる必要がある

## 2. 高度な設計を提案し、賛同を得る ~15 min

- DB の Auto Increment を使う方法
  - 単一サーバ：SPOF になるから微妙
  - 分散サーバ：サーバー i は、ID を i から始め、サーバー台数 n ずつインクリメントしてく
    - 作成日時でソートできない、サーバー台数を増減させられないから微妙
- **Twitter の snowflake アプローチ**が要件を満たせる
  ![image](/images/202502_system_design/ch7_snowflake.png)

## 3. 設計の深掘り ~25 min

- データセンター ID,マシン ID は、`2^5=32` 種類表現可能。
- タイムスタンプは、カスタムエポックタイム（サービス開始時を 0 とする）を使えば、桁数が足りなくなるまでの時間を稼げる。

## 4. まとめ・追加 ~5 min

- 高可用性をどう担保するか。（ID ジェネレーターはミッションクリティカルなはず。）

# Chapter 8: Design A Url Shortener

# Chapter 9: Design A Web Crawler

# Chapter 10: Design A Notification System

# Chapter 11: Design A News Feed System

# Chapter 12: Design A Chat System

# Chapter 13: Design A Search Autocomplete System

# Chapter 14: Design Youtube

# Chapter 15: Design Google Drive

# Chapter 16: The Learning Continues
